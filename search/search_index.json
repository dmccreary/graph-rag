{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome","text":"<p>Welcome to our website.</p>"},{"location":"contact/","title":"Contact","text":"<p>Please contact me on LinkedIn</p> <p>Thanks! - Dan</p>"},{"location":"glossary/","title":"Glossary of Terms","text":""},{"location":"glossary/#iso-definition","title":"ISO Definition","text":"<p>A term definition is considered to be consistent with ISO metadata registry guideline 11179 if it meets the following criteria:</p> <ol> <li>Precise</li> <li>Concise</li> <li>Distinct</li> <li>Non-circular</li> <li>Unencumbered with business rules</li> </ol>"},{"location":"glossary/#graph-retrieval-augmented-generation","title":"Graph Retrieval-Augmented Generation","text":"<p>Abbreviation: GraphRAG A methodology that enhances Retrieval-Augmented Generation (RAG) by leveraging graph data structures. GraphRAG retrieves elements such as nodes, triples, paths, or subgraphs from a pre-constructed graph database, allowing for more precise and context-aware generation by considering the interconnections between texts\u200b(GraphRAG-Survey).</p>"},{"location":"glossary/#graph-neural-networks","title":"Graph Neural Networks","text":"<p>Abbreviation: GNNs A class of deep learning models specifically designed to process data structured as graphs. GNNs use a message-passing framework where information is aggregated from neighboring nodes and edges to update node representations. They are used in GraphRAG to model graph data for retrieval and generation\u200b(GraphRAG-Survey).</p>"},{"location":"glossary/#text-attributed-graphs","title":"Text-Attributed Graphs","text":"<p>Abbreviation: TAGs A universal format for graph data used in GraphRAG, where nodes and edges are associated with textual attributes. TAGs can represent knowledge graphs and other graph structures, enabling the retrieval of complex relational knowledge for use in generation tasks\u200b(GraphRAG-Survey).</p>"},{"location":"glossary/#query-focused-summarization","title":"Query-Focused Summarization","text":"<p>Abbreviation: QFS A task in natural language processing where the goal is to generate a summary of a document or set of documents that is focused on a specific query. GraphRAG enhances QFS by retrieving relevant subgraphs that capture the broader context and interconnections within the graph structure\u200b(GraphRAG-Survey).</p>"},{"location":"glossary/#graph-based-indexing","title":"Graph-Based Indexing","text":"<p>Abbreviation: G-Indexing A method used in GraphRAG to enhance the efficiency and speed of querying operations on graph databases. It influences subsequent retrieval methods and determines how the graph data is structured for optimal retrieval\u200b(GraphRAG-Survey).</p>"},{"location":"glossary/#query-expansion","title":"Query Expansion","text":"<p>A pre-processing technique used in query enhancement to improve search results by supplementing or refining the original query with additional relevant terms or concepts. It aims to capture lexical variations and expand the information content of the query\u200b(GraphRAG-Survey).</p>"},{"location":"glossary/#query-decomposition","title":"Query Decomposition","text":"<p>A technique that breaks down the original user query into smaller, more specific sub-queries. Each sub-query focuses on a particular aspect of the original query, making it easier to retrieve pertinent information and reduce the complexity of language queries\u200b(GraphRAG-Survey).</p>"},{"location":"glossary/#knowledge-merging","title":"Knowledge Merging","text":"<p>A post-retrieval enhancement strategy in GraphRAG that involves combining multiple pieces of retrieved information to provide a comprehensive view. This process assists in consolidating knowledge, improving the relevance and completeness of the final retrieved results\u200b(GraphRAG-Survey).</p>"},{"location":"glossary/#knowledge-pruning","title":"Knowledge Pruning","text":"<p>A technique used after initial retrieval to refine and improve the quality of the retrieved information by removing redundant or less relevant data. It aims to ensure that the final results are highly pertinent to the user's query, enhancing the relevance of the information presented\u200b(GraphRAG-Survey).</p>"},{"location":"glossary/#graph-enhanced-generation","title":"Graph-Enhanced Generation","text":"<p>Abbreviation: G-Generation The phase in GraphRAG where meaningful outputs or responses are synthesized based on the retrieved graph data. This stage involves taking the query, retrieved graph elements, and an optional prompt as inputs to generate a contextually relevant and accurate response\u200b(GraphRAG-Survey).</p>"},{"location":"glossary/#hybrid-granularities","title":"Hybrid Granularities","text":"<p>A retrieval approach in GraphRAG that combines multiple granularities, such as nodes, triplets, paths, and subgraphs, to capture both detailed relationships and broader contextual understanding. This method enhances the relevance and comprehensiveness of the retrieved data by balancing between retrieval content and efficiency\u200b(GraphRAG-Survey).</p>"},{"location":"glossary/#language-models","title":"Language Models","text":"<p>Abbreviation: LMs Language models (LMs) are advanced AI models designed to understand and generate human language. They are mainly classified into two types: discriminative models, like BERT and RoBERTa, which focus on tasks such as text classification, and generative models, like GPT-3 and GPT-4, which are used for tasks like machine translation and text generation\u200b(GraphRAG-Survey).</p>"},{"location":"glossary/#knowledge-base-question-answering","title":"Knowledge Base Question Answering","text":"<p>Abbreviation: KBQA A task in natural language processing focused on answering user queries based on external knowledge bases. KBQA methods are typically categorized into Information Retrieval (IR)-based methods, which retrieve information from knowledge graphs, and Semantic Parsing (SP)-based methods, which generate logical forms to query knowledge bases\u200b(GraphRAG-Survey).</p>"},{"location":"glossary/#subgraphs","title":"Subgraphs","text":"<p>In GraphRAG, subgraphs refer to comprehensive subsets of a graph that encapsulate relational contexts within a larger structure. Retrieving subgraphs allows for capturing complex patterns, sequences, and dependencies, which are crucial for a deeper understanding of semantic connections in graph-based tasks\u200b(GraphRAG-Survey).</p>"},{"location":"glossary/#paths","title":"Paths","text":"<p>Paths represent sequences of relationships between entities within a graph. In GraphRAG, retrieving paths enhances contextual understanding and reasoning capabilities by capturing complex relationships and dependencies\u200b(GraphRAG-Survey).</p>"},{"location":"glossary/#triplets","title":"Triplets","text":"<p>Triplets in graph databases consist of entities and their relationships, represented as subject-predicate-object tuples. This structured representation is used in GraphRAG to retrieve and understand relational data within a graph\u200b(GraphRAG-Survey).</p>"},{"location":"glossary/#language-models_1","title":"Language Models","text":"<p>Abbreviation: LMs Language Models are advanced AI models used in natural language processing. They excel in understanding, generating, and reasoning with text. LMs can be used as discriminative models like BERT for tasks such as classification, or generative models like GPT for tasks such as text generation. In GraphRAG, LMs serve as retrievers by interpreting natural language queries and retrieving relevant graph data\u200b(GraphRAG-Survey).</p>"},{"location":"glossary/#graph-neural-networks_1","title":"Graph Neural Networks","text":"<p>Abbreviation: GNNs GNNs are a class of deep learning models designed to handle graph-structured data. They operate by aggregating information from a node's neighbors to generate node embeddings, which can then be used for various tasks, such as node classification or graph-based retrieval. In GraphRAG, GNNs are often employed to encode graph data and guide retrieval processes\u200b(GraphRAG-Survey).</p>"},{"location":"glossary/#graph-based-indexing_1","title":"Graph-Based Indexing","text":"<p>Graph-Based Indexing is a method for organizing and indexing graph data to optimize retrieval operations. This involves mapping node and edge properties, establishing pointers between connected nodes, and organizing the data to support efficient traversal and retrieval. It plays a crucial role in enhancing query efficiency in GraphRAG\u200b(GraphRAG-Survey).</p>"},{"location":"glossary/#vector-indexing","title":"Vector Indexing","text":"<p>Vector Indexing involves converting graph data into vector representations to facilitate fast retrieval. This is particularly useful for entity linking and rapid query processing, where vector search algorithms like Locality Sensitive Hashing (LSH) are applied. It enables efficient searches and helps maintain structural information during retrieval\u200b(GraphRAG-Survey).</p>"},{"location":"glossary/#non-parametric-retriever","title":"Non-parametric Retriever","text":"<p>Non-parametric retrievers are based on heuristic rules or traditional graph search algorithms. They do not rely on deep-learning models, making them efficient for retrieval tasks that require high speed. These methods typically involve pre-processing steps like entity linking and are used in GraphRAG for tasks like subgraph extraction\u200b(GraphRAG-Survey).</p>"},{"location":"glossary/#lm-based-retriever","title":"LM-based Retriever","text":"<p>LM-based retrievers leverage the natural language processing capabilities of language models to retrieve relevant graph data based on text queries. These models are particularly effective for interpreting and processing diverse queries in GraphRAG. They are used to generate reasoning paths and assist in retrieving the most relevant graph elements\u200b(GraphRAG-Survey).</p>"},{"location":"glossary/#gnn-based-retriever","title":"GNN-based Retriever","text":"<p>GNN-based retrievers use Graph Neural Networks to understand and process graph structures. They encode graph data, score different retrieval granularities based on similarity to the query, and guide the retrieval process within GraphRAG. These retrievers are particularly adept at handling complex graph data structures\u200b(GraphRAG-Survey).</p>"},{"location":"glossary/#hybrid-granularities_1","title":"Hybrid Granularities","text":"<p>Hybrid Granularities involve retrieving graph data at multiple levels of detail, such as nodes, triplets, paths, and subgraphs, to capture both fine-grained and broad contextual information. This approach enhances the relevance and comprehensiveness of the retrieved data, making it useful for complex queries within GraphRAG\u200b(GraphRAG-Survey).</p> <p>4o</p>"},{"location":"glossary/#you-said","title":"You said:","text":"<p>add RAG to this list</p>"},{"location":"glossary/#chatgpt-said","title":"ChatGPT said:","text":"<p>ChatGPT</p>"},{"location":"glossary/#retrieval-augmented-generation","title":"Retrieval-Augmented Generation","text":"<p>Abbreviation: RAG Retrieval-Augmented Generation is a methodology that integrates external knowledge retrieval with the generation process of language models. By dynamically querying a large text corpus, RAG enhances the contextual depth, factual accuracy, and relevance of the content generated by language models. It addresses challenges such as hallucinations, lack of domain-specific knowledge, and outdated information by incorporating relevant factual knowledge into the responses\u200b(GraphRAG-Survey)\u200b(GraphRAG-Survey).</p> <p>4o</p>"},{"location":"glossary/#you-said_1","title":"You said:","text":"<p>In the attached paper, what are the key steps in a GraphRAG process?</p>"},{"location":"glossary/#chatgpt-said_1","title":"ChatGPT said:","text":"<p>ChatGPT</p> <p>The key steps in a GraphRAG process, as outlined in the paper, are:</p>"},{"location":"glossary/#1-graph-based-indexing-g-indexing","title":"1. Graph-Based Indexing (G-Indexing)","text":"<p>This initial phase involves constructing or identifying a graph database that aligns with the downstream tasks. The indexing process typically includes mapping node and edge properties, establishing pointers between connected nodes, and organizing the data to support fast traversal and retrieval operations. The quality of this step directly impacts the efficiency and effectiveness of the retrieval process.</p>"},{"location":"glossary/#2-graph-guided-retrieval-g-retrieval","title":"2. Graph-Guided Retrieval (G-Retrieval)","text":"<p>Following the indexing phase, the retrieval phase focuses on extracting relevant information from the graph database based on the user query. This involves selecting the most pertinent graph elements, such as entities, triplets, paths, or subgraphs, using retrieval algorithms. The goal is to find the graph elements that best match the query and support the next stage of generation.</p>"},{"location":"glossary/#3-graph-enhanced-generation-g-generation","title":"3. Graph-Enhanced Generation (G-Generation)","text":"<p>In the final phase, the retrieved graph elements are used to generate meaningful responses or outputs. This stage involves taking the query, the retrieved graph elements, and an optional prompt as inputs for a generation model, which produces the final response. The process is enhanced by the structural and relational knowledge embedded in the graph data.</p> <p>These steps outline the comprehensive workflow of GraphRAG, emphasizing the importance of each phase in achieving accurate, contextually relevant responses based on graph-structured data\u200b(GraphRAG-Survey).</p> <p>4o</p>"},{"location":"glossary/#you-said_2","title":"You said:","text":"<p>According to the paper, what role does entity extraction play in GraphRAG? Where does it fit in the steps?</p>"},{"location":"glossary/#chatgpt-said_2","title":"ChatGPT said:","text":"<p>ChatGPT</p> <p>Entity extraction in the GraphRAG process plays a critical role in identifying and linking entities mentioned in the input query to corresponding entities in a knowledge graph. This step is essential for effectively retrieving relevant information and establishing connections between the textual data and the structured graph data.</p>"},{"location":"glossary/#role-of-entity-extraction","title":"Role of Entity Extraction:","text":"<ul> <li>Entity extraction is often considered a pre-processing step in GraphRAG. It involves identifying key entities within the user's query and linking them to their corresponding nodes in the graph database. This ensures that the retrieval process can focus on the correct parts of the graph, thereby enhancing the relevance and accuracy of the retrieved information.</li> <li>It is particularly crucial in the Graph-Guided Retrieval phase, where entities identified in the text are mapped to their graph representations. This mapping allows the retrieval algorithms to more accurately extract the relevant subgraphs, nodes, or paths that correspond to the query.</li> </ul>"},{"location":"glossary/#placement-in-the-graphrag-steps","title":"Placement in the GraphRAG Steps:","text":"<ul> <li>Entity Extraction typically occurs at the beginning of the Graph-Guided Retrieval phase. After the graph-based indexing phase, where the graph is prepared and indexed for efficient querying, entity extraction takes place to identify which parts of the graph are relevant to the query. This step directly influences the subsequent retrieval processes, ensuring that the retrieval is focused and efficient.</li> </ul> <p>Entity extraction is thus a foundational step in aligning the unstructured text query with the structured graph data, enabling the GraphRAG system to retrieve and generate more contextually relevant responses\u200b(GraphRAG-Survey)\u200b(GraphRAG-Survey).</p> <p>4o</p>"},{"location":"glossary/#you-said_3","title":"You said:","text":"<p>Add CSQA to the list</p>"},{"location":"glossary/#chatgpt-said_3","title":"ChatGPT said:","text":"<p>ChatGPT</p>"},{"location":"glossary/#complex-sequential-question-answering","title":"Complex Sequential Question Answering","text":"<p>Abbreviation: CSQA Complex Sequential Question Answering refers to a task in natural language processing that involves answering a series of interrelated questions where the context or the answers to previous questions impact subsequent questions. This task requires handling complex dependencies and reasoning chains, often relying on structured knowledge bases or graphs to provide accurate and context-aware responses. In GraphRAG, CSQA tasks benefit from the ability to retrieve and reason over graph-structured data that captures these intricate relationships\u200b(GraphRAG-Survey)\u200b(GraphRAG-Survey).</p> <p>4o</p>"},{"location":"how-we-built-this-site/","title":"How We Built This Site","text":"<p>This page describes how we built this website and some of  the rationale behind why we made various design choices.</p>"},{"location":"how-we-built-this-site/#python","title":"Python","text":"<p>MicroSims are about how we use generative AI to create animations and simulations.  The language of AI is Python.  So we wanted to create a site that could be easily understood by Python developers.</p>"},{"location":"how-we-built-this-site/#mkdocs-vs-docusaurus","title":"Mkdocs vs. Docusaurus","text":"<p>There are two main tools used by Python developers to write documentation: Mkdocs and Docusaurus.  Mkdocs is easier to use and more popular than Docusaurus. Docusaurus is also optimized for single-page applications. Mkdocs also has an extensive library of themes and plugins. None of us are experts in JavaScript or React. Based on our ChatGPT Analysis of the Tradeoffs we chose mkdocs for this site management.</p>"},{"location":"how-we-built-this-site/#github-and-github-pages","title":"GitHub and GitHub Pages","text":"<p>GitHub is a logical choice to store our  site source code and documentation.  GitHub also has a Custom GitHub Action that does auto-deployment if any files on the site change. We don't currently have this action enabled, but other teams can use this feature if they don't have the ability to do a local build with mkdocs.</p> <p>GitHub also has Issues,  Projects and releases that we can use to manage our bugs and tasks.</p> <p>The best practice for low-cost websites that have public-only content is GitHub Pages. Mkdocs has a command (<code>mkdocs gh-deploy</code>) that does deployment directly to GitHub Pages.  This was an easy choice to make.</p>"},{"location":"how-we-built-this-site/#github-clone","title":"GitHub Clone","text":"<p>If you would like to clone this repository, here are the commands:</p> <pre><code>mkdir projects\ncd projects\ngit clone https://github.com/dmccreary/microsims\n</code></pre>"},{"location":"how-we-built-this-site/#after-changes","title":"After Changes","text":"<p>After you make local changes you must do the following:</p> <pre><code># add the new files to a a local commit transaction\ngit add FILES\n# Execute the a local commit with a message about what and why you are doing the commit\ngit commit -m \"comment\"\n# Update the central GitHub repository\ngit push\n</code></pre>"},{"location":"how-we-built-this-site/#material-theme","title":"Material Theme","text":"<p>We had several options when picking a mkdocs theme:</p> <ol> <li>Mkdocs default</li> <li>Readthedocs</li> <li>Third-Party Themes See Ranking</li> </ol> <p>The Material Theme had 16K stars.  No other theme had over a few hundred. This was also an easy design decision.</p> <p>One key criterial was the social Open Graph tags so that when our users post a link to a simulation, the image of the simulation is included in the link.  Since Material supported this, we used the Material theme. You can see our ChatGPT Design Decision Analysis if you want to check our decision process.</p>"},{"location":"how-we-built-this-site/#enable-edit-icon","title":"Enable Edit Icon","text":"<p>To enable the Edit icon on all pages, you must add the edit_uri and the content.action.edit under the theme features area.</p> <pre><code>edit_uri: edit/master/docs/\n</code></pre> <pre><code>    theme:\n        features:\n            - content.action.edit\n</code></pre>"},{"location":"how-we-built-this-site/#conda-vs-venv","title":"Conda vs VENV","text":"<p>There are two choices for virtual environments.  We can use the native Python venv or use Conda.  venv is simle but is only designed for pure Python projects.  We imagine that this site could use JavaScript and other langauges in the future, so we picked Conda. There is nothing on this microsite that prevents you from using one or the other.  See the ChatGPT Analysis Here.</p> <p>Here is the conda script that we ran to create a new mkdocs environment that also supports the material social imaging libraries.</p> <pre><code>conda deactivate\nconda create -n mkdocs python=3\nconda activate mkdocs\npip install mkdocs \"mkdocs-material[imaging]\"\n</code></pre>"},{"location":"how-we-built-this-site/#mkdocs-commands","title":"Mkdocs Commands","text":"<p>There are three simple mkdoc commands we use.</p>"},{"location":"how-we-built-this-site/#local-build","title":"Local Build","text":"<pre><code>mkdocs build\n</code></pre> <p>This builds your website in a folder called <code>site</code>.  Use this to test that the mkdocs.yml site is working and does not have any errors.</p>"},{"location":"how-we-built-this-site/#run-a-local-server","title":"Run a Local Server","text":"<pre><code>mkdocs serve\n</code></pre> <p>This runs a server on <code>http://localhost:8000</code>. Use this to test the display formatting locally before you push your code up to the GitHub repo.</p> <pre><code>mkdoc gh-deploy\n</code></pre> <p>This pushes everything up to the GitHub Pages site. Note that it does not commit your code to GitHub.</p>"},{"location":"how-we-built-this-site/#mkdocs-material-social-tags","title":"Mkdocs Material Social Tags","text":"<p>We are using the Material Social tags.  This is a work in progress!</p> <p>Here is what we have learned.</p> <ol> <li>There are extensive image processing libraries that can't be installed with just pip.  You will need to run a tool like brew on the Mac to get the libraries installed.</li> <li>Even after <code>brew</code> installs the libraries, you have to get your environment to find the libraries.  The only way I could get that to work was to set up a local UNIX environment variable.</li> </ol> <p>Here is the brew command that I ran:</p> <pre><code>brew install cairo freetype libffi libjpeg libpng zlib\n</code></pre> <p>I then had to add the following to my ~/.zshrc file:</p> <pre><code>export DYLD_FALLBACK_LIBRARY_PATH=/opt/homebrew/lib\n</code></pre> <p>Note that I am running on a Mac with Apple silicon.  This means that the image libraries that brew downloads must be specific to the Mac Arm instruction set.</p> <ul> <li>Cover images for blog post #4364</li> <li>Discussion on overriding the Social Card Image</li> </ul>"},{"location":"license/","title":"Creative Commons License","text":"<p>All content in this repository is governed by the following license agreement:</p>"},{"location":"license/#license-type","title":"License Type","text":"<p>Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0 DEED)</p>"},{"location":"license/#link-to-license-agreement","title":"Link to License Agreement","text":"<p>https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en</p>"},{"location":"license/#your-rights","title":"Your Rights","text":"<p>You are free to:</p> <ul> <li>Share \u2014 copy and redistribute the material in any medium or format</li> <li>Adapt \u2014 remix, transform, and build upon the material</li> </ul> <p>The licensor cannot revoke these freedoms as long as you follow the license terms.</p>"},{"location":"license/#restrictions","title":"Restrictions","text":"<ul> <li>Attribution \u2014 You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.</li> <li>NonCommercial \u2014 You may not use the material for commercial purposes.</li> <li>ShareAlike \u2014 If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original.</li> <li>No additional restrictions \u2014 You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.</li> </ul> <p>Notices</p> <p>You do not have to comply with the license for elements of the material in the public domain or where your use is permitted by an applicable exception or limitation.</p> <p>No warranties are given. The license may not give you all of the permissions necessary for your intended use. For example, other rights such as publicity, privacy, or moral rights may limit how you use the material.</p> <p>This deed highlights only some of the key features and terms of the actual license. It is not a license and has no legal value. You should carefully review all of the terms and conditions of the actual license before using the licensed material.</p>"},{"location":"references/","title":"Graph RAG References","text":"<ol> <li>Graph Retrieval-Augmented Generation: A Survey</li> <li>From Local to Global: A Graph RAG Approach to Query-Focused Summarization</li> </ol>"}]}